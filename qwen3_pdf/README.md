# Configuration
Minimum CUDA version = 11.8

Read main.py to adjust file paths.

main.py is configured to run the `Qwen/Qwen3-VL-2B-Instruct` model. Requires 8GB of VRAM.

There are various models available that can be deployed by changing `Qwen/Qwen3-VL-2B-Instruct` to the following:
`Qwen/Qwen3-VL-4B-Instruct` (Requires 16GB VRAM)
`Qwen/Qwen3-VL-8B-Instruct` (Requires 32GB VRAM)
`Qwen/Qwen3-VL-30B-A3B-Instruct` (Requires 80GB VRAM)


